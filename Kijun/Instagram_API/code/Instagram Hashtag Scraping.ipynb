{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instagram Account Information\n",
    "# ID = \"jdsc_ds_team\"\n",
    "# PW = \"jdscjdsc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of scraping function\n",
    "def scraping(tag_list):\n",
    "    \n",
    "    # Define dataframe to store hashtag information\n",
    "    tag_df = pd.DataFrame(columns=[\"Date\",\"Hashtag\",\"Number of Posts\",\"Freq(mins)\"])\n",
    "    \n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    \n",
    "    for tag in tag_list:\n",
    "        # Directory of ChromeDriver \n",
    "        driver = webdriver.Chrome(\"/usr/local/bin/chromedriver\")\n",
    "        driver.get(\"https://www.instagram.com/explore/tags/\"+str(tag))\n",
    "        soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "        \n",
    "        tagname = tag\n",
    "        \n",
    "        # Extract total number of posts\n",
    "        nposts = soup.find(\"span\",{\"class\":\"g47SY\"}).text\n",
    "        print(tagname) # check the target keyword\n",
    "        print(\"number of posts:\",nposts) # check the total number of posts\n",
    "        \n",
    "        # Extract all post links from \"explore tags\" page\n",
    "        # NOTE : Class name may change in the website code\n",
    "        # Needed to extract post frequency of recent posts\n",
    "        myli = []\n",
    "        for a in soup.find_all(\"a\",href=True):\n",
    "             myli.append(a[\"href\"])\n",
    "                \n",
    "        # Keep link of only 1st and 9th most recent post\n",
    "        newmyli = [x for x in myli if x.startswith(\"/p\")]\n",
    "        \n",
    "        del newmyli[:9]\n",
    "        del newmyli[9:]\n",
    "        del newmyli[1:8]\n",
    "        \n",
    "        timediff = []\n",
    "        \n",
    "        # EXtract the posting time of 1st and 9th most recent\n",
    "        for j in range(len(newmyli)):\n",
    "            driver.get('https://www.instagram.com'+str(newmyli[j]))\n",
    "            soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    " \n",
    "            for i in soup.findAll('time'):\n",
    "                if i.has_attr('datetime'):\n",
    "                    timediff.append(i['datetime'])\n",
    "                    \n",
    "        # Calculate time difference between posts\n",
    "        # For obtaining posting frequency\n",
    "        datetimeFormat = '%Y-%m-%dT%H:%M:%S.%fZ'\n",
    "        diff = datetime.datetime.strptime(timediff[0], datetimeFormat)\\\n",
    "                - datetime.datetime.strptime(timediff[1], datetimeFormat)\n",
    "        pfreq = int(diff.total_seconds()/(9*60))\n",
    "        print(\"frequency of posts:\",pfreq)\n",
    "        \n",
    "        # Set Time\n",
    "        date = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "        \n",
    "        # Add hashtag info to dataframe\n",
    "        s = pd.Series([date, tagname, nposts, pfreq],index=tag_df.columns)\n",
    "        tag_df = tag_df.append(s,ignore_index=True)\n",
    "        \n",
    "        driver.quit()\n",
    "        \n",
    "        # Wait 2 seconds\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Add information to csv file\n",
    "    tag_df.to_csv(\"/scraping_data/stest.csv\",encoding=\"utf-8\",mode=\"a\",header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tag_list\n",
    "tag_list = [\n",
    "            \"石原さとみ\",\n",
    "            \"嵐\",\n",
    "            \"菅田将暉\",\n",
    "            \"ローラ\",\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "while(True):\n",
    "    if datetime.datetime.now().minute%10 != 9:\n",
    "        time.sleep(58)\n",
    "        continue\n",
    "    while datetime.datetime.now().second != 59:\n",
    "        time.sleep(1)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    print(\"Scraping starts!\",datetime.datetime.now())\n",
    "\n",
    "    scraping(tag_list)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.4",
    "jupytext_version": "1.1.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
